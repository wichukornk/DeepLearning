{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "066c1119",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/recommenders/examples/featurization#turning_categorical_features_into_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff5c1585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': 45.0,\n",
      " 'movie_genres': array([7]),\n",
      " 'movie_id': b'357',\n",
      " 'movie_title': b\"One Flew Over the Cuckoo's Nest (1975)\",\n",
      " 'raw_user_age': 46.0,\n",
      " 'timestamp': 879024327,\n",
      " 'user_gender': True,\n",
      " 'user_id': b'138',\n",
      " 'user_occupation_label': 4,\n",
      " 'user_occupation_text': b'doctor',\n",
      " 'user_rating': 4.0,\n",
      " 'user_zip_code': b'53211'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 12:45:13.471508: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
    "\n",
    "for x in ratings.take(1).as_numpy_iterator():\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ded240",
   "metadata": {},
   "source": [
    "## StringLookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f766434",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_title_lookup = keras.layers.StringLookup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7558f94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_title_lookup.adapt(ratings.map(lambda x: x[\"movie_title\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "123882ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['[UNK]', 'Star Wars (1977)', 'Contact (1997)']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Vocabulary: {movie_title_lookup.get_vocabulary()[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebb353b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int64, numpy=array([ 1, 58])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_title_lookup([\"Star Wars (1977)\", \"One Flew Over the Cuckoo's Nest (1975)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "495e9389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int64, numpy=array([1, 0])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_title_lookup([\"Star Wars (1977)\", \"อาตมาฟ้าผ่า (2023)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f773ce4d",
   "metadata": {},
   "source": [
    "## Hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5808685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set up a large number of bins to reduce the chance of hash collisions.\n",
    "num_hashing_bins = 200_000\n",
    "\n",
    "movie_title_hashing = keras.layers.Hashing(\n",
    "    num_bins=num_hashing_bins\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4784114f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int64, numpy=array([101016,  96565])>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_title_hashing([\"Star Wars (1977)\", \"One Flew Over the Cuckoo's Nest (1975)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "635b3b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int64, numpy=array([101016,  11243])>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_title_hashing([\"Star Wars (1977)\", \"อาตมาฟ้าผ่า (2023)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35d317f",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ede411c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:vocab_size is deprecated, please use vocabulary_size.\n"
     ]
    }
   ],
   "source": [
    "movie_title_embedding = keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=movie_title_lookup.vocab_size(),\n",
    "    output_dim=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f8df968",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_title_model = keras.Sequential([movie_title_lookup, movie_title_embedding])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ecb89b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=['Star Wars (1977)']. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
       "array([[-0.03976804, -0.0415496 , -0.01106708,  0.01324985, -0.00261353,\n",
       "        -0.02245682,  0.04873098,  0.02778157,  0.03387476, -0.04363858,\n",
       "        -0.03595002,  0.01188491, -0.00124532, -0.0250195 , -0.04118379,\n",
       "        -0.02669857, -0.04516503,  0.02814424,  0.04141983, -0.00908929,\n",
       "         0.01978109,  0.01217794,  0.00402678,  0.0276508 , -0.03961364,\n",
       "         0.01118432, -0.0254912 , -0.01327118,  0.03487224,  0.0377438 ,\n",
       "         0.00740225,  0.04585507]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_title_model([\"Star Wars (1977)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "666bd227",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=['อาตมาฟ้าผ่า (2023)']. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
       "array([[ 0.00870454,  0.01667029, -0.03952014,  0.03339828,  0.01844809,\n",
       "        -0.01724365,  0.04233545, -0.02298212,  0.01944694,  0.02790696,\n",
       "         0.00716276,  0.00797569,  0.02400592,  0.02485884,  0.01714841,\n",
       "        -0.02012392, -0.01661407, -0.0033948 , -0.01215196, -0.01838628,\n",
       "        -0.02694302,  0.04167242, -0.03338395,  0.0347913 , -0.0431049 ,\n",
       "         0.03890902,  0.03594854,  0.01720348, -0.03736428,  0.03122853,\n",
       "         0.0263013 ,  0.00762074]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_title_model([\"อาตมาฟ้าผ่า (2023)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33f1866f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=['Transformer (2023)']. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
       "array([[ 0.00870454,  0.01667029, -0.03952014,  0.03339828,  0.01844809,\n",
       "        -0.01724365,  0.04233545, -0.02298212,  0.01944694,  0.02790696,\n",
       "         0.00716276,  0.00797569,  0.02400592,  0.02485884,  0.01714841,\n",
       "        -0.02012392, -0.01661407, -0.0033948 , -0.01215196, -0.01838628,\n",
       "        -0.02694302,  0.04167242, -0.03338395,  0.0347913 , -0.0431049 ,\n",
       "         0.03890902,  0.03594854,  0.01720348, -0.03736428,  0.03122853,\n",
       "         0.0263013 ,  0.00762074]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_title_model([\"Transformer (2023)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7544351",
   "metadata": {},
   "source": [
    "## Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d42c6c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:vocab_size is deprecated, please use vocabulary_size.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:vocab_size is deprecated, please use vocabulary_size.\n"
     ]
    }
   ],
   "source": [
    "title_text = keras.layers.TextVectorization(\n",
    "    max_tokens=movie_title_lookup.vocab_size(),\n",
    "    output_mode='int',\n",
    "    output_sequence_length=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea4e3abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_text.adapt(movie_title_lookup.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "552bfcba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[ 67   1 267   2]], shape=(1, 4), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for row in ratings.batch(1).map(lambda x: x[\"movie_title\"]).take(1):\n",
    "    print(title_text(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7632e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        max_tokens = 10_000\n",
    "\n",
    "        self.title_embedding = tf.keras.Sequential([\n",
    "          movie_title_lookup,\n",
    "          tf.keras.layers.Embedding(movie_title_lookup.vocab_size(), 32)\n",
    "        ])\n",
    "        self.title_text_embedding = tf.keras.Sequential([\n",
    "          tf.keras.layers.TextVectorization(max_tokens=movie_title_lookup.vocab_size()),\n",
    "          tf.keras.layers.Embedding(max_tokens, 32, mask_zero=True),\n",
    "          # We average the embedding of individual words to get one embedding vector\n",
    "          # per title.\n",
    "          tf.keras.layers.GlobalAveragePooling1D(),\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.concat([\n",
    "            self.title_embedding(inputs[\"movie_title\"]),\n",
    "            self.title_text_embedding(inputs[\"movie_title\"]),\n",
    "        ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86786f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:vocab_size is deprecated, please use vocabulary_size.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:vocab_size is deprecated, please use vocabulary_size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:vocab_size is deprecated, please use vocabulary_size.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:vocab_size is deprecated, please use vocabulary_size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed representations: [[ 0.01668649 -0.02470998  0.00087453 -0.01957372 -0.03918434  0.03484757\n",
      "   0.04127902  0.04971499  0.00717026 -0.03783311  0.02099004 -0.0333066\n",
      "   0.00397264 -0.00721947  0.01684313  0.00868932  0.04040403  0.02759239\n",
      "   0.02041711 -0.04278275 -0.03107814  0.03146942 -0.04349905 -0.04913602\n",
      "  -0.03564036  0.01462188  0.03932277 -0.02871143  0.00535514 -0.03882653\n",
      "   0.03556228 -0.0487872   0.00037591  0.0005873  -0.00334165  0.00749038\n",
      "  -0.02618823 -0.01187599 -0.00856781 -0.00213595 -0.00520481  0.01038452\n",
      "  -0.01337023 -0.00917381 -0.00410407 -0.00226621  0.00111128 -0.00036775\n",
      "  -0.00890375  0.00025452  0.00016249  0.00018749 -0.01879689  0.00883781\n",
      "   0.00048551 -0.01632429 -0.00713462  0.02292983 -0.02531117 -0.01108099\n",
      "   0.00531709 -0.00898669  0.01554871 -0.00992816]]\n"
     ]
    }
   ],
   "source": [
    "movie_model = MovieModel()\n",
    "\n",
    "movie_model.title_text_embedding.layers[0].adapt(\n",
    "    movie_title_lookup.get_vocabulary())\n",
    "\n",
    "for row in ratings.batch(1).take(1):\n",
    "    print(f\"Computed representations: {movie_model(row)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5a32f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
